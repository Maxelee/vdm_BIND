[TRAINING]
# ==============================================================================
# Optimal Transport Flow Matching Configuration
# ==============================================================================
# 
# This config implements OT Flow Matching (Lipman et al., 2022) for the 
# DMO -> Hydro mapping.
#
# Key idea:
#   - Standard flow matching uses LINEAR interpolation with random pairing
#   - OT flow matching uses OPTIMAL TRANSPORT to pair x_0 and x_1
#   - This results in straighter paths through data space
#   - Better sample quality, especially for structured data
#
# Trade-offs:
#   - More expensive per step (OT computation)
#   - But may converge faster and produce better samples
#   - Particularly beneficial for astronomical data with complex structure
#
# Reference:
#   Lipman et al. (2022) "Flow Matching for Generative Modeling"
#   https://arxiv.org/abs/2210.02747
# ==============================================================================

seed = 8
dataset = IllustrisTNG
data_root = /mnt/home/mlee1/ceph/train_data_rotated2_128_cpu/train/
field = gas
boxsize = 6.25

# ==============================================================================
# TRAINING HYPERPARAMETERS
# ==============================================================================
# OT computation is O(nÂ³) for exact EMD, so smaller batch sizes help.
# Sinkhorn is faster but approximate.

batch_size = 96
accumulate_grad_batches = 1
num_workers = 20
cropsize = 128
max_epochs = 200

# ==============================================================================
# LEARNING RATE
# ==============================================================================

learning_rate = 1e-4
weight_decay = 1e-5
lr_scheduler = cosine_warmup

# ==============================================================================
# ARCHITECTURE
# ==============================================================================

embedding_dim = 96
n_blocks = 5
norm_groups = 8
n_attention_heads = 8

# Conditioning channels
conditioning_channels = 1
large_scale_channels = 3

# Fourier features and attention
use_fourier_features = True
fourier_legacy = False
add_attention = True

# Parameter conditioning
use_param_conditioning = True
param_norm_path = /mnt/home/mlee1/Sims/IllustrisTNG_extras/L50n512/SB35/SB35_param_minmax.csv

# ==============================================================================
# QUANTILE NORMALIZATION
# ==============================================================================

quantile_path = /mnt/home/mlee1/vdm_BIND/data/quantile_normalizer_stellar.pkl
use_quantile_normalization = True

# ==============================================================================
# OT FLOW MATCHING PARAMETERS
# ==============================================================================

# x0_mode: How to initialize source distribution
#   - 'zeros': Start from zeros
#   - 'noise': Start from Gaussian noise
#   - 'dm_copy': Start from DM condition (physically motivated)
x0_mode = dm_copy

# OT method:
#   - 'exact': Exact Earth Mover's Distance (EMD) - slower but precise
#   - 'sinkhorn': Entropic OT - faster but approximate
# For batch sizes <= 64, 'exact' is recommended
# For larger batches, 'sinkhorn' is more practical
ot_method = exact

# Sinkhorn regularization (only used if ot_method = sinkhorn)
# Smaller = closer to exact OT but slower convergence
# Typical values: 0.001 to 0.1
ot_reg = 0.01

# Use OT during training
# Set to False to compare with standard (random pairing) flow matching
use_ot_training = True

# OT warmup epochs
# Start with random pairing for first N epochs, then switch to OT
# This can help with early training stability
ot_warmup_epochs = 0

# Stochastic interpolant: Add noise during interpolation
use_stochastic_interpolant = False
sigma = 0.0

# Number of sampling steps
# OT flow matching typically needs similar steps to linear flow matching
n_sampling_steps = 50

# ==============================================================================
# EMA (Exponential Moving Average)
# ==============================================================================

enable_ema = True
ema_decay = 0.9999
ema_update_after_step = 0
ema_update_every = 1

# ==============================================================================
# EARLY STOPPING
# ==============================================================================

enable_early_stopping = True
early_stopping_patience = 300

# ==============================================================================
# GRADIENT MONITORING
# ==============================================================================

enable_gradient_monitoring = True
gradient_log_frequency = 100

# ==============================================================================
# TRAINING DATA
# ==============================================================================

limit_train_samples = None
limit_val_samples = None
limit_train_batches = 1.0

# ==============================================================================
# LOGGING
# ==============================================================================

tb_logs = /mnt/home/mlee1/ceph/tb_logs3
model_name = ot_flow_3ch
version = 0

# ==============================================================================
# SPEED OPTIMIZATIONS
# ==============================================================================
# precision: "32" (default), "16-mixed" (faster on modern GPUs), "bf16-mixed"
# compile_model: Use torch.compile for ~10-30% speedup (requires PyTorch 2.0+)

precision = 16-mixed
compile_model = True
