[TRAINING]
# ==============================================================================
# DDPM/Score Model Configuration
# ==============================================================================
# 
# This config uses the score_models package to train diffusion models
# with Denoising Score Matching (DSM) instead of VDM ELBO.
#
# Key differences from VDM:
#   - Uses VP-SDE (beta_min/beta_max) instead of learned gamma schedule
#   - DSM loss instead of diffusion + latent + reconstruction
#   - Compatible with NCSNpp and DDPM architectures
# ==============================================================================

seed = 8
dataset = IllustrisTNG
data_root = /mnt/home/mlee1/ceph/train_data_rotated2_128_cpu/train/
field = gas
boxsize = 6.25 

# ==============================================================================
# TRAINING HYPERPARAMETERS
# ==============================================================================
# NOTE: NCSNpp with attention is memory-intensive due to activations
# With DDP on 4x A100-40GB, batch_size=16 means 4 per GPU
# If still OOM, try batch_size=8 or disable attention
#
# Effective batch size = batch_size * accumulate_grad_batches * num_gpus
# With batch_size=16, accumulate=4, 4 GPUs: effective=256

batch_size = 16
accumulate_grad_batches = 4
num_workers = 8
cropsize = 128
max_epochs = 250

# ==============================================================================
# LEARNING RATE
# ==============================================================================

learning_rate = 1e-4
lr_scheduler = cosine

# ==============================================================================
# ARCHITECTURE
# ==============================================================================
# Options: ncsnpp, ddpm
# ncsnpp: Yang Song's NCSN++ from "Score-Based Generative Modeling through SDEs"
# ddpm: Jonathan Ho's DDPM architecture

architecture = ncsnpp

# Base number of features
nf = 96

# Channel multipliers for each resolution level
# For 128x128 input: 128 -> 64 -> 32 -> 16 -> 8
ch_mult = 1,2,4,8

# Number of residual blocks per resolution (DDPM only)
num_res_blocks = 2

# Use attention blocks
attention = True

# Dropout rate
dropout = 0.1

# ==============================================================================
# SDE CONFIGURATION
# ==============================================================================
# VP-SDE (Variance Preserving): Like DDPM, uses beta schedule
# VE-SDE (Variance Exploding): Like NCSN, uses sigma schedule

sde = vp

# VP-SDE parameters (used when sde = vp)
beta_min = 0.1
beta_max = 20.0

# VE-SDE parameters (used when sde = ve)
sigma_min = 0.01
sigma_max = 50.0

# ==============================================================================
# CONDITIONING
# ==============================================================================

# Large-scale conditioning channels (in addition to DM condition)
large_scale_channels = 3

# Use cosmological/astrophysical parameters for vector conditioning
# If True, the 35 parameters from the training data will be passed to the model
use_param_conditioning = True

# Number of parameters in the conditions vector
n_params = 35

# ==============================================================================
# EMA (EXPONENTIAL MOVING AVERAGE)
# ==============================================================================

enable_ema = True
ema_decay = 0.9999
ema_update_after_step = 1000
ema_update_every = 1

# ==============================================================================
# STELLAR NORMALIZATION
# ==============================================================================

quantile_path = data/quantile_normalizer_stellar.pkl

# ==============================================================================
# MONITORING
# ==============================================================================

enable_early_stopping = False
early_stopping_patience = 50
enable_gradient_monitoring = True
gradient_log_frequency = 50

# ==============================================================================
# TRAINING DATA
# ==============================================================================

# Set to a number for testing (e.g., 1000), None for full dataset
limit_train_samples = 1000
limit_val_samples = 200
limit_train_batches = 1.0

# ==============================================================================
# LOGGING
# ==============================================================================

model_name = ddpm_ncsnpp_vp_test
tb_logs = /mnt/home/mlee1/ceph/tb_logs
version = 3
