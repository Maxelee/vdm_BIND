{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b0f01f87",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/sw/nix/store/gpkc8q6zjnp3n3h3w9hbmbj6gjbxs85w-python-3.10.10-view/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/mnt/sw/nix/store/6qvrglgqdpwhbw9zv2nh07fpd7a4wq31-py-torchvision-0.15.2/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n",
      "Seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "GPU: NVIDIA A100-SXM4-80GB\n"
     ]
    }
   ],
   "source": [
    "# Setup path and imports\n",
    "import sys\n",
    "sys.path.insert(0, '/mnt/home/mlee1/vdm_BIND')\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from lightning.pytorch import seed_everything\n",
    "\n",
    "# Set seed for reproducibility\n",
    "seed_everything(42)\n",
    "\n",
    "# Check GPU availability\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f\"Using device: {device}\")\n",
    "if device == 'cuda':\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79fd5a7f",
   "metadata": {},
   "source": [
    "## 1. Available Methods and Backbones\n",
    "\n",
    "Let's see what's available in the new API:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cd410dd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "AVAILABLE METHODS\n",
      "==================================================\n",
      "  â€¢ consistency\n",
      "  â€¢ flow\n",
      "  â€¢ vdm\n",
      "\n",
      "==================================================\n",
      "AVAILABLE BACKBONES\n",
      "==================================================\n",
      "  â€¢ dit\n",
      "  â€¢ dit-b\n",
      "  â€¢ dit-l\n",
      "  â€¢ dit-s\n",
      "  â€¢ dit-xl\n",
      "  â€¢ fno\n",
      "  â€¢ fno-b\n",
      "  â€¢ fno-l\n",
      "  â€¢ fno-s\n",
      "  â€¢ fno-xl\n",
      "  â€¢ unet\n",
      "  â€¢ unet-b\n",
      "  â€¢ unet-l\n",
      "  â€¢ unet-s\n"
     ]
    }
   ],
   "source": [
    "from vdm.methods import list_methods, create_method\n",
    "from vdm.backbones import list_backbones, create_backbone\n",
    "\n",
    "print(\"=\" * 50)\n",
    "print(\"AVAILABLE METHODS\")\n",
    "print(\"=\" * 50)\n",
    "for method in list_methods():\n",
    "    print(f\"  â€¢ {method}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"AVAILABLE BACKBONES\")\n",
    "print(\"=\" * 50)\n",
    "for backbone in list_backbones():\n",
    "    print(f\"  â€¢ {backbone}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2565d225",
   "metadata": {},
   "source": [
    "## 2. Creating Backbones\n",
    "\n",
    "All backbones follow a unified interface:\n",
    "```python\n",
    "output = backbone(x_t, t, conditioning, param_conditioning)\n",
    "```\n",
    "\n",
    "Where:\n",
    "- `x_t`: (B, C, H, W) - Noisy input\n",
    "- `t`: (B,) - Time in [0, 1]\n",
    "- `conditioning`: (B, C_cond, H, W) - Spatial conditioning (DM + large-scale)\n",
    "- `param_conditioning`: (B, N_params) - Cosmological parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f4c72b3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Legacy Fourier features enabled (backward compatibility):\n",
      "  - Exponential frequencies: 2^(-2:1) * 2Ï€\n",
      "  - Applied to first channel of concatenated input\n",
      "  - 8 Fourier features\n",
      "  - Total input channels: 15\n",
      "âš™ï¸  ParamEmbedding: Unconditional mode (n_params=0)\n",
      "âœ“ Parameter conditioning enabled:\n",
      "  - Time embedding dim: 256\n",
      "  - Param embedding dim: 256\n",
      "  - Total condition dim: 512\n",
      "âœ“ Channel progression (encoder): [64, 128, 256]\n",
      "âœ“ Final decoder channels: 64 (GroupNorm groups: 8)\n",
      "âœ“ Parameter predictor added (predicts 0 params)\n",
      "UNet-S parameters: 10,139,781\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/home/mlee1/venvs/torch3/lib/python3.10/site-packages/torch/nn/init.py:511: UserWarning: Initializing zero-element tensors is a no-op\n",
      "  warnings.warn(\"Initializing zero-element tensors is a no-op\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "INITIALIZED DiT MODEL\n",
      "============================================================\n",
      "  Image size: 128x128\n",
      "  Patch size: 4\n",
      "  Num patches: 1024\n",
      "  Hidden size: 384\n",
      "  Depth: 12\n",
      "  Heads: 6\n",
      "  MLP ratio: 4.0\n",
      "  Parameters: 6 (0=unconditional)\n",
      "  Conditioning: 1 + 3 large-scale\n",
      "  Total params: 32,674,224\n",
      "============================================================\n",
      "\n",
      "DiT-S parameters: 32,674,224\n",
      "\n",
      "============================================================\n",
      "INITIALIZED FNO2d\n",
      "============================================================\n",
      "  Input channels: 3\n",
      "  Output channels: 3\n",
      "  Conditioning channels: 4\n",
      "  Hidden channels: 32\n",
      "  FNO layers: 4\n",
      "  Param conditioning: True (6 params)\n",
      "  Total parameters: 2,147,267\n",
      "============================================================\n",
      "\n",
      "FNO-S parameters: 2,147,267\n"
     ]
    }
   ],
   "source": [
    "# Create different backbone architectures\n",
    "\n",
    "# Common parameters\n",
    "backbone_params = {\n",
    "    'input_channels': 3,\n",
    "    'output_channels': 3,\n",
    "    'conditioning_channels': 1,\n",
    "    'large_scale_channels': 3,\n",
    "    'param_dim': 6,  # Cosmological parameters\n",
    "    'img_size': 128,\n",
    "}\n",
    "\n",
    "# Create a small UNet backbone\n",
    "unet_backbone = create_backbone('unet-s', **backbone_params)\n",
    "print(f\"UNet-S parameters: {sum(p.numel() for p in unet_backbone.parameters()):,}\")\n",
    "\n",
    "# Create a small DiT backbone  \n",
    "dit_backbone = create_backbone('dit-s', **backbone_params)\n",
    "print(f\"DiT-S parameters: {sum(p.numel() for p in dit_backbone.parameters()):,}\")\n",
    "\n",
    "# Create a small FNO backbone\n",
    "fno_backbone = create_backbone('fno-s', **backbone_params)\n",
    "print(f\"FNO-S parameters: {sum(p.numel() for p in fno_backbone.parameters()):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4873fe5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UNet output shape: torch.Size([2, 3, 128, 128])\n",
      "DiT output shape: torch.Size([2, 3, 128, 128])\n",
      "FNO output shape: torch.Size([2, 3, 128, 128])\n"
     ]
    }
   ],
   "source": [
    "# Test backbone interface\n",
    "batch_size = 2\n",
    "x_t = torch.randn(batch_size, 3, 128, 128)  # Noisy input\n",
    "t = torch.rand(batch_size)  # Time in [0, 1]\n",
    "conditioning = torch.randn(batch_size, 4, 128, 128)  # DM + 3 large-scale\n",
    "param_cond = torch.randn(batch_size, 6)  # Cosmological params\n",
    "\n",
    "# Test UNet\n",
    "with torch.no_grad():\n",
    "    out_unet = unet_backbone(x_t, t, conditioning, param_cond)\n",
    "    print(f\"UNet output shape: {out_unet.shape}\")\n",
    "\n",
    "# Test DiT\n",
    "with torch.no_grad():\n",
    "    out_dit = dit_backbone(x_t, t, conditioning, param_cond)\n",
    "    print(f\"DiT output shape: {out_dit.shape}\")\n",
    "\n",
    "# Test FNO\n",
    "with torch.no_grad():\n",
    "    out_fno = fno_backbone(x_t, t, conditioning, param_cond)\n",
    "    print(f\"FNO output shape: {out_fno.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b55924a",
   "metadata": {},
   "source": [
    "## 3. Creating Methods\n",
    "\n",
    "Methods wrap backbones and provide:\n",
    "- `compute_loss(x, conditioning, params)` - Training loss\n",
    "- `sample(conditioning, n_samples, n_steps)` - Generation\n",
    "- `draw_samples(x, conditioning, params, ...)` - BIND-compatible interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "54bd40af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Legacy Fourier features enabled (backward compatibility):\n",
      "  - Exponential frequencies: 2^(-2:1) * 2Ï€\n",
      "  - Applied to first channel of concatenated input\n",
      "  - 8 Fourier features\n",
      "  - Total input channels: 15\n",
      "âš™ï¸  ParamEmbedding: Unconditional mode (n_params=0)\n",
      "âœ“ Parameter conditioning enabled:\n",
      "  - Time embedding dim: 256\n",
      "  - Param embedding dim: 256\n",
      "  - Total condition dim: 512\n",
      "âœ“ Channel progression (encoder): [64, 128, 256]\n",
      "âœ“ Final decoder channels: 64 (GroupNorm groups: 8)\n",
      "âœ“ Parameter predictor added (predicts 0 params)\n",
      "\n",
      "============================================================\n",
      "VDM METHOD INITIALIZED\n",
      "============================================================\n",
      "  Backbone: UNetBackbone\n",
      "  Gamma range: [-13.3, 5.0]\n",
      "  Noise schedule: fixed_linear\n",
      "  Sampling steps: 250\n",
      "  Channel weights: (1.0, 1.0, 1.0)\n",
      "  Focal loss: False\n",
      "============================================================\n",
      "\n",
      "VDM+UNet parameters: 10,139,781\n",
      "\n",
      "============================================================\n",
      "INITIALIZED DiT MODEL\n",
      "============================================================\n",
      "  Image size: 128x128\n",
      "  Patch size: 4\n",
      "  Num patches: 1024\n",
      "  Hidden size: 384\n",
      "  Depth: 12\n",
      "  Heads: 6\n",
      "  MLP ratio: 4.0\n",
      "  Parameters: 6 (0=unconditional)\n",
      "  Conditioning: 1 + 3 large-scale\n",
      "  Total params: 32,674,224\n",
      "============================================================\n",
      "\n",
      "\n",
      "============================================================\n",
      "FLOW MATCHING METHOD INITIALIZED\n",
      "============================================================\n",
      "  Backbone: DiTBackbone\n",
      "  Sampling steps: 50\n",
      "  Stochastic: False (sigma=0.0)\n",
      "  x0 mode: zeros\n",
      "============================================================\n",
      "\n",
      "Flow+DiT parameters: 32,674,224\n",
      "\n",
      "============================================================\n",
      "INITIALIZED FNO2d\n",
      "============================================================\n",
      "  Input channels: 3\n",
      "  Output channels: 3\n",
      "  Conditioning channels: 4\n",
      "  Hidden channels: 32\n",
      "  FNO layers: 4\n",
      "  Param conditioning: True (6 params)\n",
      "  Total parameters: 2,147,267\n",
      "============================================================\n",
      "\n",
      "\n",
      "============================================================\n",
      "CONSISTENCY METHOD INITIALIZED\n",
      "============================================================\n",
      "  Backbone: FNOBackbone\n",
      "  Sigma range: [0.002, 80.0]\n",
      "  Sampling steps: 1\n",
      "  Denoising pretraining: True\n",
      "============================================================\n",
      "\n",
      "Consistency+FNO parameters: 2,147,267\n"
     ]
    }
   ],
   "source": [
    "# Create methods with different backbones\n",
    "\n",
    "# VDM with UNet (classic setup)\n",
    "vdm_unet = create_method(\n",
    "    'vdm',\n",
    "    backbone_type='unet-s',\n",
    "    img_size=128,\n",
    "    param_dim=6,\n",
    "    conditioning_channels=1,\n",
    "    large_scale_channels=3,\n",
    "    learning_rate=1e-4,\n",
    ")\n",
    "print(f\"VDM+UNet parameters: {sum(p.numel() for p in vdm_unet.parameters()):,}\")\n",
    "\n",
    "# Flow Matching with DiT\n",
    "flow_dit = create_method(\n",
    "    'flow',\n",
    "    backbone_type='dit-s',\n",
    "    img_size=128,\n",
    "    param_dim=6,\n",
    "    conditioning_channels=1,\n",
    "    large_scale_channels=3,\n",
    "    n_sampling_steps=50,\n",
    ")\n",
    "print(f\"Flow+DiT parameters: {sum(p.numel() for p in flow_dit.parameters()):,}\")\n",
    "\n",
    "# Consistency with FNO (fast sampling!)\n",
    "cons_fno = create_method(\n",
    "    'consistency',\n",
    "    backbone_type='fno-s',\n",
    "    img_size=128,\n",
    "    param_dim=6,\n",
    "    conditioning_channels=1,\n",
    "    large_scale_channels=3,\n",
    "    n_sampling_steps=1,  # Single step!\n",
    ")\n",
    "print(f\"Consistency+FNO parameters: {sum(p.numel() for p in cons_fno.parameters()):,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62406dc9",
   "metadata": {},
   "source": [
    "## 4. Loading Data\n",
    "\n",
    "Let's load a small subset of training data (1000 samples as requested):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4967dd05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Loaded DM stats: mean=9.915499, std=0.467967\n",
      "âœ“ Loaded Gas stats: mean=9.177344, std=0.410510\n",
      "âœ“ Loading stellar Z-score stats from: /mnt/home/mlee1/vdm_BIND/data/stellar_normalization_stats.npz\n",
      "  mean=6.995926, std=1.100350\n",
      "\n",
      "ðŸ“Š NORMALIZATION CONFIG (3-channel mode):\n",
      "  DM input: mean=9.9777, std=0.4139\n",
      "  DM target: mean=9.9155, std=0.4680\n",
      "  Gas target: mean=9.1773, std=0.4105\n",
      "  Stars target: mean=6.9959, std=1.1004\n",
      "âœ“ Loaded DM stats: mean=9.915499, std=0.467967\n",
      "âœ“ Loaded Gas stats: mean=9.177344, std=0.410510\n",
      "âœ“ Loading stellar Z-score stats from: /mnt/home/mlee1/vdm_BIND/data/stellar_normalization_stats.npz\n",
      "  mean=6.995926, std=1.100350\n",
      "\n",
      "ðŸ“Š NORMALIZATION CONFIG (3-channel mode):\n",
      "  DM input: mean=9.9777, std=0.4139\n",
      "  DM target: mean=9.9155, std=0.4680\n",
      "  Gas target: mean=9.1773, std=0.4105\n",
      "  Stars target: mean=6.9959, std=1.1004\n",
      "ðŸ“‚ Loading file list from cache: /mnt/home/mlee1/ceph/train_data_rotated2_128_cpu/train/file_list_cache.txt\n",
      "   Loaded 408860 files in 0.48s\n",
      "Found 408860 total files\n",
      "âš¡ FAST ABLATION MODE: Randomly selecting 1000 training samples\n",
      "  â†’ Selected 1000 random samples from full dataset\n",
      "ðŸ“‚ Loading file list from cache: /mnt/home/mlee1/ceph/train_data_rotated2_128_cpu/train/file_list_cache.txt\n",
      "   Loaded 408860 files in 0.08s\n",
      "Found 408860 total files\n",
      "âš¡ FAST ABLATION MODE: Randomly selecting 1000 training samples\n",
      "  â†’ Selected 1000 random samples from full dataset\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'AstroDataModule' object has no attribute 'train_dataset'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 16\u001b[0m\n\u001b[1;32m      7\u001b[0m datamodule \u001b[38;5;241m=\u001b[39m get_astro_data(\n\u001b[1;32m      8\u001b[0m     dataset\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mIllustrisTNG\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m      9\u001b[0m     data_root\u001b[38;5;241m=\u001b[39mdata_root,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     12\u001b[0m     stage\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfit\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     13\u001b[0m     limit_train_samples\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1000\u001b[39m)\u001b[38;5;66;03m#  Limit to 1000 samples for quick testing)\u001b[39;00m\n\u001b[1;32m     15\u001b[0m datamodule\u001b[38;5;241m.\u001b[39msetup(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfit\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 16\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining samples: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(datamodule\u001b[38;5;241m.\u001b[39mtrain_dataset)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mValidation samples: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(datamodule\u001b[38;5;241m.\u001b[39mval_dataset)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'AstroDataModule' object has no attribute 'train_dataset'"
     ]
    }
   ],
   "source": [
    "from vdm.astro_dataset import get_astro_data\n",
    "\n",
    "# Load training data\n",
    "data_root = '/mnt/home/mlee1/ceph/train_data_rotated2_128_cpu/train/'\n",
    "\n",
    "# Use a small batch size for this tutorial\n",
    "datamodule = get_astro_data(\n",
    "    dataset='IllustrisTNG',\n",
    "    data_root=data_root,\n",
    "    batch_size=32,\n",
    "    num_workers=4,\n",
    "    stage='fit',\n",
    "    limit_train_samples=1000)#  Limit to 1000 samples for quick testing)\n",
    "\n",
    "datamodule.setup('fit')\n",
    "print(f\"Training samples: {len(datamodule.train_dataset)}\")\n",
    "print(f\"Validation samples: {len(datamodule.val_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "13ff0aa3",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "list indices must be integers or slices, not str",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28miter\u001b[39m(train_loader))\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Unpack batch\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m condition, target, params \u001b[38;5;241m=\u001b[39m \u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcondition\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m, batch[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtarget\u001b[39m\u001b[38;5;124m'\u001b[39m], batch[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mparams\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCondition shape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcondition\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)  \u001b[38;5;66;03m# (B, 1+3, H, W) = DM + large-scale\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTarget shape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtarget\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)  \u001b[38;5;66;03m# (B, 3, H, W) = [DM_hydro, Gas, Stars]\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: list indices must be integers or slices, not str"
     ]
    }
   ],
   "source": [
    "# Inspect a batch\n",
    "train_loader = datamodule.train_dataloader()\n",
    "batch = next(iter(train_loader))\n",
    "\n",
    "# Unpack batch\n",
    "condition, target, params = batch['condition'], batch['target'], batch['params']\n",
    "\n",
    "print(f\"Condition shape: {condition.shape}\")  # (B, 1+3, H, W) = DM + large-scale\n",
    "print(f\"Target shape: {target.shape}\")  # (B, 3, H, W) = [DM_hydro, Gas, Stars]\n",
    "print(f\"Params shape: {params.shape}\")  # (B, N_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce0fc438",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize a sample\n",
    "idx = 0\n",
    "\n",
    "fig, axes = plt.subplots(2, 4, figsize=(16, 8))\n",
    "\n",
    "# Condition channels\n",
    "axes[0, 0].imshow(condition[idx, 0].numpy(), cmap='viridis')\n",
    "axes[0, 0].set_title('DM Condition')\n",
    "axes[0, 1].imshow(condition[idx, 1].numpy(), cmap='viridis')\n",
    "axes[0, 1].set_title('Large-scale 1')\n",
    "axes[0, 2].imshow(condition[idx, 2].numpy(), cmap='viridis')\n",
    "axes[0, 2].set_title('Large-scale 2')\n",
    "axes[0, 3].imshow(condition[idx, 3].numpy(), cmap='viridis')\n",
    "axes[0, 3].set_title('Large-scale 3')\n",
    "\n",
    "# Target channels\n",
    "axes[1, 0].imshow(target[idx, 0].numpy(), cmap='inferno')\n",
    "axes[1, 0].set_title('DM Hydro (target)')\n",
    "axes[1, 1].imshow(target[idx, 1].numpy(), cmap='inferno')\n",
    "axes[1, 1].set_title('Gas (target)')\n",
    "axes[1, 2].imshow(target[idx, 2].numpy(), cmap='inferno')\n",
    "axes[1, 2].set_title('Stars (target)')\n",
    "axes[1, 3].axis('off')\n",
    "\n",
    "for ax in axes.flat:\n",
    "    ax.axis('off')\n",
    "    \n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3cbca54",
   "metadata": {},
   "source": [
    "## 5. Quick Training Demo\n",
    "\n",
    "Let's do a quick training run with VDM + UNet-S on our small dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eaabd9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightning.pytorch import Trainer\n",
    "from lightning.pytorch.callbacks import ModelCheckpoint\n",
    "from lightning.pytorch.loggers import TensorBoardLogger\n",
    "\n",
    "# Create a fresh VDM model for training\n",
    "model = create_method(\n",
    "    'vdm',\n",
    "    backbone_type='unet-s',\n",
    "    img_size=128,\n",
    "    param_dim=params.shape[1],\n",
    "    conditioning_channels=1,\n",
    "    large_scale_channels=3,\n",
    "    learning_rate=1e-4,\n",
    ")\n",
    "\n",
    "print(f\"Model parameters: {sum(p.numel() for p in model.parameters()):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1739cffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick training (just a few epochs for demo)\n",
    "logger = TensorBoardLogger(\n",
    "    save_dir='/mnt/home/mlee1/ceph/tb_logs_tutorial',\n",
    "    name='vdm_unet_tutorial',\n",
    "    version=0\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    max_epochs=5,  # Just a few epochs for demo\n",
    "    accelerator='gpu' if device == 'cuda' else 'cpu',\n",
    "    devices=1,\n",
    "    logger=logger,\n",
    "    enable_checkpointing=True,\n",
    "    log_every_n_steps=10,\n",
    "    limit_train_batches=0.5,  # Use only 50% of training data per epoch\n",
    "    limit_val_batches=0.2,\n",
    ")\n",
    "\n",
    "print(\"Starting training...\")\n",
    "trainer.fit(model, datamodule)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0400fb8",
   "metadata": {},
   "source": [
    "## 6. Sampling / Generation\n",
    "\n",
    "Now let's generate samples using our trained model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af719e2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move model to GPU and set to eval mode\n",
    "model = model.to(device).eval()\n",
    "\n",
    "# Get a batch for conditioning\n",
    "val_loader = datamodule.val_dataloader()\n",
    "val_batch = next(iter(val_loader))\n",
    "\n",
    "condition = val_batch['condition'].to(device)\n",
    "target = val_batch['target'].to(device)\n",
    "params = val_batch['params'].to(device)\n",
    "\n",
    "print(f\"Condition: {condition.shape}\")\n",
    "print(f\"Target: {target.shape}\")\n",
    "print(f\"Params: {params.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8a47d08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate samples using the draw_samples interface (BIND compatible)\n",
    "n_samples = 4  # Generate 4 samples\n",
    "\n",
    "with torch.no_grad():\n",
    "    # Use just the first condition for demo\n",
    "    cond_single = condition[:1]  # (1, 4, 128, 128)\n",
    "    param_single = params[:1]  # (1, N_params)\n",
    "    \n",
    "    # Generate multiple realizations\n",
    "    samples = model.draw_samples(\n",
    "        x=cond_single.expand(n_samples, -1, -1, -1),\n",
    "        conditioning=cond_single.expand(n_samples, -1, -1, -1),\n",
    "        conditional_params=param_single.expand(n_samples, -1),\n",
    "        n_sampling_steps=50,  # Use 50 steps for VDM\n",
    "    )\n",
    "    \n",
    "print(f\"Generated samples shape: {samples.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbfa597d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize generated samples vs ground truth\n",
    "fig, axes = plt.subplots(n_samples + 1, 3, figsize=(12, 4*(n_samples+1)))\n",
    "\n",
    "channel_names = ['DM Hydro', 'Gas', 'Stars']\n",
    "\n",
    "# Ground truth (first row)\n",
    "for c in range(3):\n",
    "    im = axes[0, c].imshow(target[0, c].cpu().numpy(), cmap='inferno')\n",
    "    axes[0, c].set_title(f'Ground Truth - {channel_names[c]}')\n",
    "    axes[0, c].axis('off')\n",
    "    plt.colorbar(im, ax=axes[0, c], fraction=0.046)\n",
    "\n",
    "# Generated samples\n",
    "for i in range(n_samples):\n",
    "    for c in range(3):\n",
    "        im = axes[i+1, c].imshow(samples[i, c].cpu().numpy(), cmap='inferno')\n",
    "        axes[i+1, c].set_title(f'Sample {i+1} - {channel_names[c]}')\n",
    "        axes[i+1, c].axis('off')\n",
    "        plt.colorbar(im, ax=axes[i+1, c], fraction=0.046)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c908e7d2",
   "metadata": {},
   "source": [
    "## 7. Config Factory\n",
    "\n",
    "The new config factory makes it easy to generate training configs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d8f5c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from configs.config_factory import ConfigFactory\n",
    "\n",
    "# List available presets\n",
    "print(\"Methods:\", ConfigFactory.list_methods())\n",
    "print(\"Backbones:\", ConfigFactory.list_backbones())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5862f13e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a config for Flow + DiT\n",
    "config = ConfigFactory.create(\n",
    "    method='flow',\n",
    "    backbone='dit-s',\n",
    "    model_name='flow_dit_tutorial',\n",
    "    batch_size=64,\n",
    "    max_epochs=100,\n",
    ")\n",
    "\n",
    "# Print some key settings\n",
    "print(\"Generated config:\")\n",
    "for key in ['method', 'backbone_type', 'model_name', 'batch_size', 'learning_rate', 'n_sampling_steps']:\n",
    "    print(f\"  {key}: {config.get(key, 'N/A')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46a782fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save config to file\n",
    "ConfigFactory.save(config, '/mnt/home/mlee1/vdm_BIND/configs/tutorial_flow_dit.ini')\n",
    "print(\"Config saved to: configs/tutorial_flow_dit.ini\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cb1646a",
   "metadata": {},
   "source": [
    "## 8. Training from Command Line\n",
    "\n",
    "You can train using `train_zoo.py` from the command line:\n",
    "\n",
    "```bash\n",
    "# With auto-generated config\n",
    "python train_zoo.py --method vdm --backbone unet-s\n",
    "\n",
    "# With saved config\n",
    "python train_zoo.py --config configs/tutorial_flow_dit.ini\n",
    "\n",
    "# List available options\n",
    "python train_zoo.py --list\n",
    "\n",
    "# Generate config only (don't train)\n",
    "python train_zoo.py --method consistency --backbone fno-s --generate-config\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c78088c",
   "metadata": {},
   "source": [
    "## 9. Comparison: Method vs Backbone\n",
    "\n",
    "Let's create a quick comparison showing how different methods work with the same backbone:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a27c7240",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare loss computation across methods\n",
    "methods_to_compare = ['vdm', 'flow', 'consistency']\n",
    "backbone_type = 'unet-s'\n",
    "\n",
    "# Create models\n",
    "models = {}\n",
    "for method in methods_to_compare:\n",
    "    models[method] = create_method(\n",
    "        method,\n",
    "        backbone_type=backbone_type,\n",
    "        img_size=128,\n",
    "        param_dim=6,\n",
    "        conditioning_channels=1,\n",
    "        large_scale_channels=3,\n",
    "    ).to(device)\n",
    "    print(f\"{method.upper()}: {sum(p.numel() for p in models[method].parameters()):,} params\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba948468",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute loss for each method on same batch\n",
    "print(\"\\nLoss computation comparison:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "for method_name, method_model in models.items():\n",
    "    method_model.train()\n",
    "    \n",
    "    # Compute loss\n",
    "    loss_dict = method_model.compute_loss(\n",
    "        x=target[:8].to(device),  # Use small batch\n",
    "        conditioning=condition[:8].to(device),\n",
    "        params=params[:8].to(device),\n",
    "    )\n",
    "    \n",
    "    loss = loss_dict['loss'].item()\n",
    "    print(f\"{method_name.upper():12s}: loss = {loss:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5d974b5",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "The new Generative Zoo API provides:\n",
    "\n",
    "1. **Unified Backbone Interface** - All architectures (UNet, DiT, FNO) follow the same API\n",
    "2. **Modular Methods** - VDM, Flow Matching, and Consistency training paradigms\n",
    "3. **Easy Configuration** - ConfigFactory for generating training configs\n",
    "4. **BIND Compatibility** - `draw_samples()` interface works with existing BIND pipeline\n",
    "5. **Systematic Comparison** - Mix and match methods with backbones\n",
    "\n",
    "### Quick Reference\n",
    "\n",
    "| Method | Sampling Steps | Best For |\n",
    "|--------|----------------|----------|\n",
    "| VDM | 250-1000 | Quality |\n",
    "| Flow | 50-100 | Balance |\n",
    "| Consistency | 1-5 | Speed |\n",
    "\n",
    "| Backbone | Parameters | Best For |\n",
    "|----------|------------|----------|\n",
    "| UNet | ~30M | General purpose |\n",
    "| DiT | ~50M | Scalability |\n",
    "| FNO | ~10M | Multi-scale physics |"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
