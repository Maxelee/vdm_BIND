{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33682a49",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Add project root to path\n",
    "PROJECT_ROOT = Path('/mnt/home/mlee1/vdm_BIND')\n",
    "sys.path.insert(0, str(PROJECT_ROOT))\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorboard.backend.event_processing import event_accumulator\n",
    "import glob\n",
    "from collections import defaultdict\n",
    "\n",
    "# Setup publication-quality plotting\n",
    "plt.rcParams.update({\n",
    "    'font.size': 14,\n",
    "    'font.family': 'serif',\n",
    "    'axes.labelsize': 14,\n",
    "    'axes.titlesize': 16,\n",
    "    'xtick.labelsize': 12,\n",
    "    'ytick.labelsize': 12,\n",
    "    'legend.fontsize': 11,\n",
    "    'figure.figsize': (12, 8),\n",
    "    'figure.dpi': 150,\n",
    "    'savefig.dpi': 300,\n",
    "    'savefig.bbox': 'tight',\n",
    "})\n",
    "\n",
    "# Output directory for figures\n",
    "FIGURE_DIR = PROJECT_ROOT / 'analysis' / 'figures' / 'training'\n",
    "FIGURE_DIR.mkdir(parents=True, exist_ok=True)\n",
    "print(f\"Figures will be saved to: {FIGURE_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36d89092",
   "metadata": {},
   "source": [
    "## Configuration\n",
    "\n",
    "Select the model type and version to analyze."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d3132aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# MODEL CONFIGURATION - MODIFY THIS SECTION\n",
    "# ============================================================================\n",
    "\n",
    "# Model type: 'clean' (3-channel joint) or 'triple' (3 separate VDMs)\n",
    "MODEL_TYPE = 'clean'\n",
    "\n",
    "# Model name and version\n",
    "MODEL_NAME = 'clean_vdm_aggressive_stellar'\n",
    "VERSION = 2\n",
    "\n",
    "# TensorBoard logs root\n",
    "TB_LOGS_ROOT = Path('/mnt/home/mlee1/ceph/tb_logs')\n",
    "\n",
    "# Build log path\n",
    "LOG_PATH = TB_LOGS_ROOT / MODEL_NAME / f'version_{VERSION}'\n",
    "print(f\"Loading logs from: {LOG_PATH}\")\n",
    "\n",
    "# Verify path exists\n",
    "if not LOG_PATH.exists():\n",
    "    print(f\"❌ Log path does not exist!\")\n",
    "    print(f\"Available versions:\")\n",
    "    available = list((TB_LOGS_ROOT / MODEL_NAME).glob('version_*'))\n",
    "    for v in sorted(available):\n",
    "        print(f\"  - {v.name}\")\n",
    "else:\n",
    "    print(f\"✓ Log path found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46eea455",
   "metadata": {},
   "source": [
    "## Load TensorBoard Events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e36ec590",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_tensorboard_logs(log_path):\n",
    "    \"\"\"\n",
    "    Load all scalar metrics from TensorBoard event files.\n",
    "    \n",
    "    Returns:\n",
    "        dict: {metric_name: {'steps': [...], 'values': [...]}}\n",
    "    \"\"\"\n",
    "    event_files = list(Path(log_path).glob('events.out.tfevents.*'))\n",
    "    if not event_files:\n",
    "        raise FileNotFoundError(f\"No event files found in {log_path}\")\n",
    "    \n",
    "    print(f\"Found {len(event_files)} event file(s)\")\n",
    "    \n",
    "    metrics = defaultdict(lambda: {'steps': [], 'values': [], 'wall_times': []})\n",
    "    \n",
    "    for event_file in event_files:\n",
    "        ea = event_accumulator.EventAccumulator(\n",
    "            str(event_file),\n",
    "            size_guidance={'scalars': 0}  # Load all scalars\n",
    "        )\n",
    "        ea.Reload()\n",
    "        \n",
    "        for tag in ea.Tags()['scalars']:\n",
    "            events = ea.Scalars(tag)\n",
    "            for event in events:\n",
    "                metrics[tag]['steps'].append(event.step)\n",
    "                metrics[tag]['values'].append(event.value)\n",
    "                metrics[tag]['wall_times'].append(event.wall_time)\n",
    "    \n",
    "    # Convert to numpy arrays and sort by step\n",
    "    for tag in metrics:\n",
    "        sort_idx = np.argsort(metrics[tag]['steps'])\n",
    "        metrics[tag]['steps'] = np.array(metrics[tag]['steps'])[sort_idx]\n",
    "        metrics[tag]['values'] = np.array(metrics[tag]['values'])[sort_idx]\n",
    "        metrics[tag]['wall_times'] = np.array(metrics[tag]['wall_times'])[sort_idx]\n",
    "    \n",
    "    return dict(metrics)\n",
    "\n",
    "# Load the logs\n",
    "metrics = load_tensorboard_logs(LOG_PATH)\n",
    "print(f\"\\nLoaded {len(metrics)} metrics:\")\n",
    "for tag in sorted(metrics.keys()):\n",
    "    n_points = len(metrics[tag]['steps'])\n",
    "    print(f\"  {tag}: {n_points} points\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25a284f4",
   "metadata": {},
   "source": [
    "## Plot Overall Training/Validation Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "289de292",
   "metadata": {},
   "outputs": [],
   "source": [
    "def smooth_curve(values, weight=0.9):\n",
    "    \"\"\"Exponential moving average smoothing.\"\"\"\n",
    "    smoothed = []\n",
    "    last = values[0]\n",
    "    for v in values:\n",
    "        smoothed_val = last * weight + (1 - weight) * v\n",
    "        smoothed.append(smoothed_val)\n",
    "        last = smoothed_val\n",
    "    return np.array(smoothed)\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Left: Training loss\n",
    "ax = axes[0]\n",
    "if 'train/loss' in metrics:\n",
    "    steps = metrics['train/loss']['steps']\n",
    "    values = metrics['train/loss']['values']\n",
    "    ax.plot(steps, values, alpha=0.3, color='blue', label='Raw')\n",
    "    ax.plot(steps, smooth_curve(values), color='blue', linewidth=2, label='Smoothed')\n",
    "ax.set_xlabel('Step')\n",
    "ax.set_ylabel('Loss')\n",
    "ax.set_title('Training Loss')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Right: Validation loss\n",
    "ax = axes[1]\n",
    "if 'val/loss' in metrics:\n",
    "    steps = metrics['val/loss']['steps']\n",
    "    values = metrics['val/loss']['values']\n",
    "    ax.plot(steps, values, 'o-', color='orange', markersize=3, label='Validation')\n",
    "elif 'val/elbo' in metrics:\n",
    "    steps = metrics['val/elbo']['steps']\n",
    "    values = metrics['val/elbo']['values']\n",
    "    ax.plot(steps, values, 'o-', color='orange', markersize=3, label='Validation ELBO')\n",
    "ax.set_xlabel('Step')\n",
    "ax.set_ylabel('Loss')\n",
    "ax.set_title('Validation Loss')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.suptitle(f'{MODEL_NAME} (v{VERSION})', fontsize=16, y=1.02)\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save figure\n",
    "fig.savefig(FIGURE_DIR / f'{MODEL_NAME}_v{VERSION}_overall_loss.png')\n",
    "print(f\"Saved: {FIGURE_DIR / f'{MODEL_NAME}_v{VERSION}_overall_loss.png'}\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6019157",
   "metadata": {},
   "source": [
    "## Plot Per-Channel Losses\n",
    "\n",
    "Visualize the loss contribution from each output channel (DM Hydro, Gas, Stars)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "150fa5a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find per-channel loss metrics\n",
    "channel_metrics = {}\n",
    "channel_names = ['DM Hydro', 'Gas', 'Stars']\n",
    "channel_colors = ['#1f77b4', '#2ca02c', '#d62728']  # Blue, Green, Red\n",
    "\n",
    "# Look for various naming conventions\n",
    "for i, name in enumerate(channel_names):\n",
    "    possible_keys = [\n",
    "        f'train/loss_ch{i}',\n",
    "        f'train/channel_{i}_loss',\n",
    "        f'train/loss_channel_{i}',\n",
    "        f'train/{name.lower().replace(\" \", \"_\")}_loss',\n",
    "    ]\n",
    "    for key in possible_keys:\n",
    "        if key in metrics:\n",
    "            channel_metrics[name] = metrics[key]\n",
    "            print(f\"Found {name} loss: {key}\")\n",
    "            break\n",
    "\n",
    "# Also check for diffusion loss per channel (more common in VDM)\n",
    "if not channel_metrics:\n",
    "    print(\"\\nLooking for diffusion loss metrics...\")\n",
    "    for key in metrics:\n",
    "        if 'diffusion' in key.lower() or 'channel' in key.lower():\n",
    "            print(f\"  Found: {key}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d452d010",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot per-channel losses if available\n",
    "if channel_metrics:\n",
    "    fig, ax = plt.subplots(figsize=(12, 6))\n",
    "    \n",
    "    for i, (name, data) in enumerate(channel_metrics.items()):\n",
    "        steps = data['steps']\n",
    "        values = data['values']\n",
    "        color = channel_colors[i]\n",
    "        \n",
    "        ax.plot(steps, values, alpha=0.3, color=color)\n",
    "        ax.plot(steps, smooth_curve(values), color=color, linewidth=2, label=name)\n",
    "    \n",
    "    ax.set_xlabel('Step')\n",
    "    ax.set_ylabel('Loss')\n",
    "    ax.set_title(f'Per-Channel Training Loss - {MODEL_NAME} (v{VERSION})')\n",
    "    ax.legend()\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    fig.savefig(FIGURE_DIR / f'{MODEL_NAME}_v{VERSION}_channel_losses.png')\n",
    "    print(f\"Saved: {FIGURE_DIR / f'{MODEL_NAME}_v{VERSION}_channel_losses.png'}\")\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No per-channel loss metrics found.\")\n",
    "    print(\"Available metrics containing 'loss':\")\n",
    "    for key in sorted(metrics.keys()):\n",
    "        if 'loss' in key.lower():\n",
    "            print(f\"  {key}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "820de7c5",
   "metadata": {},
   "source": [
    "## Plot VDM Loss Components\n",
    "\n",
    "VDM has multiple loss terms: diffusion loss, latent loss, and reconstruction loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de87a846",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find VDM-specific loss components\n",
    "vdm_loss_keys = {\n",
    "    'Diffusion': ['train/diffusion_loss', 'train/loss_diffusion', 'diffusion_loss'],\n",
    "    'Latent': ['train/latent_loss', 'train/loss_latent', 'latent_loss'],\n",
    "    'Reconstruction': ['train/recons_loss', 'train/reconstruction_loss', 'recons_loss'],\n",
    "    'ELBO': ['train/elbo', 'elbo'],\n",
    "}\n",
    "\n",
    "vdm_losses = {}\n",
    "for loss_name, possible_keys in vdm_loss_keys.items():\n",
    "    for key in possible_keys:\n",
    "        if key in metrics:\n",
    "            vdm_losses[loss_name] = metrics[key]\n",
    "            print(f\"Found {loss_name}: {key}\")\n",
    "            break\n",
    "\n",
    "if vdm_losses:\n",
    "    n_losses = len(vdm_losses)\n",
    "    fig, axes = plt.subplots(1, n_losses, figsize=(5*n_losses, 5))\n",
    "    if n_losses == 1:\n",
    "        axes = [axes]\n",
    "    \n",
    "    colors = plt.cm.Set2(np.linspace(0, 1, n_losses))\n",
    "    \n",
    "    for ax, (name, data), color in zip(axes, vdm_losses.items(), colors):\n",
    "        steps = data['steps']\n",
    "        values = data['values']\n",
    "        \n",
    "        ax.plot(steps, values, alpha=0.3, color=color)\n",
    "        ax.plot(steps, smooth_curve(values), color=color, linewidth=2)\n",
    "        ax.set_xlabel('Step')\n",
    "        ax.set_ylabel('Loss')\n",
    "        ax.set_title(f'{name} Loss')\n",
    "        ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.suptitle(f'VDM Loss Components - {MODEL_NAME} (v{VERSION})', fontsize=16, y=1.02)\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    fig.savefig(FIGURE_DIR / f'{MODEL_NAME}_v{VERSION}_vdm_components.png')\n",
    "    print(f\"Saved: {FIGURE_DIR / f'{MODEL_NAME}_v{VERSION}_vdm_components.png'}\")\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No VDM-specific loss components found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d00c8fc",
   "metadata": {},
   "source": [
    "## Compare Multiple Model Versions (Optional)\n",
    "\n",
    "Compare loss curves across different model versions or architectures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79798e26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# MODEL COMPARISON CONFIGURATION\n",
    "# ============================================================================\n",
    "\n",
    "COMPARE_MODELS = True  # Set to True to enable comparison\n",
    "\n",
    "# Models to compare: list of (model_name, version, label, color)\n",
    "MODELS_TO_COMPARE = [\n",
    "    ('clean_vdm_aggressive_stellar', 2, 'Clean v2', '#1f77b4'),\n",
    "    # ('clean_vdm_aggressive_stellar', 1, 'Clean v1', '#ff7f0e'),\n",
    "    # ('clean_vdm_triple', 0, 'Triple v0', '#2ca02c'),\n",
    "]\n",
    "\n",
    "if COMPARE_MODELS and len(MODELS_TO_COMPARE) > 1:\n",
    "    print(\"Loading metrics for model comparison...\")\n",
    "    \n",
    "    comparison_data = {}\n",
    "    for model_name, version, label, color in MODELS_TO_COMPARE:\n",
    "        log_path = TB_LOGS_ROOT / model_name / f'version_{version}'\n",
    "        if log_path.exists():\n",
    "            try:\n",
    "                comparison_data[label] = {\n",
    "                    'metrics': load_tensorboard_logs(log_path),\n",
    "                    'color': color\n",
    "                }\n",
    "                print(f\"  ✓ Loaded {label}\")\n",
    "            except Exception as e:\n",
    "                print(f\"  ✗ Failed to load {label}: {e}\")\n",
    "        else:\n",
    "            print(f\"  ✗ Path not found: {log_path}\")\n",
    "else:\n",
    "    print(\"Model comparison disabled or only one model specified.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbc71f1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if COMPARE_MODELS and len(MODELS_TO_COMPARE) > 1 and comparison_data:\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "    \n",
    "    # Training loss comparison\n",
    "    ax = axes[0]\n",
    "    for label, data in comparison_data.items():\n",
    "        if 'train/loss' in data['metrics']:\n",
    "            steps = data['metrics']['train/loss']['steps']\n",
    "            values = data['metrics']['train/loss']['values']\n",
    "            ax.plot(steps, smooth_curve(values), color=data['color'], \n",
    "                   linewidth=2, label=label)\n",
    "    ax.set_xlabel('Step')\n",
    "    ax.set_ylabel('Loss')\n",
    "    ax.set_title('Training Loss Comparison')\n",
    "    ax.legend()\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Validation loss comparison\n",
    "    ax = axes[1]\n",
    "    for label, data in comparison_data.items():\n",
    "        val_key = 'val/loss' if 'val/loss' in data['metrics'] else 'val/elbo'\n",
    "        if val_key in data['metrics']:\n",
    "            steps = data['metrics'][val_key]['steps']\n",
    "            values = data['metrics'][val_key]['values']\n",
    "            ax.plot(steps, values, 'o-', color=data['color'], \n",
    "                   markersize=3, label=label)\n",
    "    ax.set_xlabel('Step')\n",
    "    ax.set_ylabel('Loss')\n",
    "    ax.set_title('Validation Loss Comparison')\n",
    "    ax.legend()\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.suptitle('Model Comparison', fontsize=16, y=1.02)\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    fig.savefig(FIGURE_DIR / 'model_comparison_losses.png')\n",
    "    print(f\"Saved: {FIGURE_DIR / 'model_comparison_losses.png'}\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3864513",
   "metadata": {},
   "source": [
    "## Summary Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2c4f028",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"Training Summary: {MODEL_NAME} (v{VERSION})\")\n",
    "print(f\"{'='*60}\\n\")\n",
    "\n",
    "# Final training loss\n",
    "if 'train/loss' in metrics:\n",
    "    final_train = metrics['train/loss']['values'][-1]\n",
    "    min_train = metrics['train/loss']['values'].min()\n",
    "    print(f\"Training Loss:\")\n",
    "    print(f\"  Final: {final_train:.4f}\")\n",
    "    print(f\"  Min:   {min_train:.4f}\")\n",
    "    print()\n",
    "\n",
    "# Final validation loss\n",
    "val_key = 'val/loss' if 'val/loss' in metrics else 'val/elbo'\n",
    "if val_key in metrics:\n",
    "    final_val = metrics[val_key]['values'][-1]\n",
    "    min_val = metrics[val_key]['values'].min()\n",
    "    best_step = metrics[val_key]['steps'][np.argmin(metrics[val_key]['values'])]\n",
    "    print(f\"Validation Loss:\")\n",
    "    print(f\"  Final: {final_val:.4f}\")\n",
    "    print(f\"  Best:  {min_val:.4f} (step {best_step})\")\n",
    "    print()\n",
    "\n",
    "# Training time\n",
    "if 'train/loss' in metrics:\n",
    "    wall_times = metrics['train/loss']['wall_times']\n",
    "    total_time = (wall_times[-1] - wall_times[0]) / 3600  # hours\n",
    "    total_steps = metrics['train/loss']['steps'][-1]\n",
    "    print(f\"Training Time:\")\n",
    "    print(f\"  Total: {total_time:.2f} hours\")\n",
    "    print(f\"  Steps: {total_steps}\")\n",
    "    print(f\"  Rate:  {total_steps/total_time:.1f} steps/hour\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
